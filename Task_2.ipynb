{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.utils import check_random_state\n",
        "import numpy as np\n",
        "\n",
        "def generate_sample_indices(random_state, n_samples):\n",
        "    \"\"\"Generate bootstrap sample indices for in-bag samples.\"\"\"\n",
        "    random_instance = check_random_state(random_state)\n",
        "    sample_indices = random_instance.randint(0, n_samples, n_samples)\n",
        "    return sample_indices\n",
        "\n",
        "def generate_unsampled_indices(random_state, n_samples):\n",
        "    \"\"\"Generate indices for out-of-bag (OOB) samples.\"\"\"\n",
        "    sample_indices = generate_sample_indices(random_state, n_samples)\n",
        "    sample_counts = np.bincount(sample_indices, minlength=n_samples)\n",
        "    unsampled_mask = sample_counts == 0\n",
        "    indices_range = np.arange(n_samples)\n",
        "    unsampled_indices = indices_range[unsampled_mask]\n",
        "    return unsampled_indices\n",
        "\n",
        "class CustomRandomForestClassifier(RandomForestClassifier):\n",
        "    def fit(self, X, y):\n",
        "        # Fit the model using the super class\n",
        "        super().fit(X, y)\n",
        "\n",
        "        # Initialize lists to store in-bag, OOB indices, and OOB losses for each tree\n",
        "        self.in_bag_indices_ = []\n",
        "        self.oob_indices_ = []\n",
        "        self.tree_weights_ = []\n",
        "\n",
        "        for estimator in self.estimators_:\n",
        "            # Generate in-bag and OOB indices\n",
        "            random_state = estimator.random_state\n",
        "            in_bag_indices = generate_sample_indices(random_state, len(X))\n",
        "            oob_indices = generate_unsampled_indices(random_state, len(X))\n",
        "\n",
        "            # Store in-bag and OOB indices\n",
        "            self.in_bag_indices_.append(in_bag_indices)\n",
        "            self.oob_indices_.append(oob_indices)\n",
        "\n",
        "            # Calculate and store OOB loss\n",
        "            if len(oob_indices) > 0:\n",
        "                oob_predictions = estimator.predict(X[oob_indices])\n",
        "                oob_loss = mean_squared_error(y[oob_indices], oob_predictions)\n",
        "                self.tree_weights_.append(np.exp(-oob_loss))\n",
        "            else:\n",
        "                self.tree_weights_.append(0)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Check if forest is fitted\n",
        "        if not hasattr(self, \"estimators_\"):\n",
        "            raise ValueError(\"The forest is not fitted yet!\")\n",
        "\n",
        "        # Aggregate predictions from all trees, weighted by their OOB loss-based weights\n",
        "        weighted_preds = np.zeros((X.shape[0], len(self.classes_)))\n",
        "        for tree, weight in zip(self.estimators_, self.tree_weights_):\n",
        "            preds = tree.predict_proba(X)\n",
        "            weighted_preds += weight * preds\n",
        "\n",
        "        final_preds = np.argmax(weighted_preds, axis=1)\n",
        "        return self.classes_[final_preds]\n",
        "\n",
        "# Example usage\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "clf = CustomRandomForestClassifier(oob_score=True)\n",
        "clf.fit(X, y)\n",
        "predictions = clf.predict(X)\n",
        "\n",
        "# Accessing in-bag and OOB data for each tree\n",
        "for i, tree in enumerate(clf.estimators_):\n",
        "    in_bag_samples_X = X[clf.in_bag_indices_[i]]\n",
        "    in_bag_samples_y = y[clf.in_bag_indices_[i]]\n",
        "    oob_samples_X = X[clf.oob_indices_[i]]\n",
        "    oob_samples_y = y[clf.oob_indices_[i]]"
      ],
      "metadata": {
        "id": "AI5qF2UQpWGa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.utils import check_random_state\n",
        "import numpy as np\n",
        "\n",
        "# Function to generate indices for random samples from a dataset\n",
        "def generate_sample_indices(random_state, n_samples):\n",
        "    \"\"\"\n",
        "    Generate random indices for selecting samples from a dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - random_state: A random number generator.\n",
        "    - n_samples: The total number of samples in the dataset.\n",
        "\n",
        "    Returns:\n",
        "    - sample_indices: An array of random sample indices.\n",
        "    \"\"\"\n",
        "    random_instance = check_random_state(random_state)\n",
        "    sample_indices = random_instance.randint(0, n_samples, n_samples)\n",
        "    return sample_indices\n",
        "\n",
        "# Function to generate indices for samples that are not selected (out-of-bag samples)\n",
        "def generate_unsampled_indices(random_state, n_samples):\n",
        "    \"\"\"\n",
        "    Generate indices for samples that are not selected (out-of-bag samples).\n",
        "\n",
        "    Parameters:\n",
        "    - random_state: A random number generator.\n",
        "    - n_samples: The total number of samples in the dataset.\n",
        "\n",
        "    Returns:\n",
        "    - unsampled_indices: An array of indices representing out-of-bag samples.\n",
        "    \"\"\"\n",
        "    sample_indices = generate_sample_indices(random_state, n_samples)\n",
        "    sample_counts = np.bincount(sample_indices, minlength=n_samples)\n",
        "    unsampled_mask = sample_counts == 0\n",
        "    indices_range = np.arange(n_samples)\n",
        "    unsampled_indices = indices_range[unsampled_mask]\n",
        "    return unsampled_indices\n",
        "\n",
        "# Custom RandomForestClassifier class\n",
        "class CustomRandomForestClassifier(RandomForestClassifier):\n",
        "    \"\"\"\n",
        "    A custom implementation of RandomForestClassifier with additional features.\n",
        "\n",
        "    This class extends the functionality of the RandomForestClassifier from scikit-learn.\n",
        "\n",
        "    Methods:\n",
        "    - fit(X, y): Fit the model to the training data.\n",
        "    - predict(X): Make predictions using the fitted model.\n",
        "\n",
        "    Attributes:\n",
        "    - in_bag_indices_: A list of indices representing samples used for training in each tree.\n",
        "    - oob_indices_: A list of indices representing out-of-bag samples for each tree.\n",
        "    - tree_weights_: A list of weights assigned to each tree based on its performance.\n",
        "\n",
        "    Example Usage:\n",
        "    - X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "    - clf = CustomRandomForestClassifier(oob_score=True)\n",
        "    - clf.fit(X, y)\n",
        "    - predictions = clf.predict(X)\n",
        "    \"\"\"\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit the custom random forest model to the training data.\n",
        "\n",
        "        Parameters:\n",
        "        - X: Input features (numpy array or pandas DataFrame).\n",
        "        - y: Target labels (numpy array or pandas Series).\n",
        "\n",
        "        Returns:\n",
        "        - self: The fitted model.\n",
        "        \"\"\"\n",
        "        # Fit the model using the superclass RandomForestClassifier\n",
        "        super().fit(X, y)\n",
        "\n",
        "        # Initialize lists to store in-bag, out-of-bag indices, and out-of-bag loss weights for each tree\n",
        "        self.in_bag_indices_ = []\n",
        "        self.oob_indices_ = []\n",
        "        self.tree_weights_ = []\n",
        "\n",
        "        for estimator in self.estimators_:\n",
        "            # Generate in-bag and out-of-bag indices for each tree\n",
        "            random_state = estimator.random_state\n",
        "            in_bag_indices = generate_sample_indices(random_state, len(X))\n",
        "            oob_indices = generate_unsampled_indices(random_state, len(X))\n",
        "\n",
        "            # Store in-bag and out-of-bag indices\n",
        "            self.in_bag_indices_.append(in_bag_indices)\n",
        "            self.oob_indices_.append(oob_indices)\n",
        "\n",
        "            # Calculate and store out-of-bag loss-based weights\n",
        "            if len(oob_indices) > 0:\n",
        "                oob_predictions = estimator.predict(X[oob_indices])\n",
        "                oob_loss = mean_squared_error(y[oob_indices], oob_predictions)\n",
        "                self.tree_weights_.append(np.exp(-oob_loss))\n",
        "            else:\n",
        "                self.tree_weights_.append(0)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions using the fitted custom random forest model.\n",
        "\n",
        "        Parameters:\n",
        "        - X: Input features for making predictions.\n",
        "\n",
        "        Returns:\n",
        "        - final_preds: Predicted class labels.\n",
        "        \"\"\"\n",
        "        # Check if the forest is fitted\n",
        "        if not hasattr(self, \"estimators_\"):\n",
        "            raise ValueError(\"The forest is not fitted yet!\")\n",
        "\n",
        "        # Aggregate predictions from all trees, weighted by their out-of-bag loss-based weights\n",
        "        weighted_preds = np.zeros((X.shape[0], len(self.classes_)))\n",
        "        for tree, weight in zip(self.estimators_, self.tree_weights_):\n",
        "            preds = tree.predict_proba(X)\n",
        "            weighted_preds += weight * preds\n",
        "\n",
        "        final_preds = np.argmax(weighted_preds, axis=1)\n",
        "        return self.classes_[final_preds]\n",
        "\n",
        "# Example usage\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "clf = CustomRandomForestClassifier(oob_score=True)\n",
        "clf.fit(X, y)\n",
        "predictions = clf.predict(X)\n",
        "\n",
        "# Accessing in-bag and out-of-bag data for each tree\n",
        "for i, tree in enumerate(clf.estimators_):\n",
        "    in_bag_samples_X = X[clf.in_bag_indices_[i]]\n",
        "    in_bag_samples_y = y[clf.in_bag_indices_[i]]\n",
        "    oob_samples_X = X[clf.oob_indices_[i]]\n",
        "    oob_samples_y = y[clf.oob_indices_[i]]"
      ],
      "metadata": {
        "id": "wir8V_qup25w"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}