{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcMu_ClljygF",
        "outputId": "25df6d1a-3f98-42d8-d960-f141e976eff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imodels\n",
            "  Downloading imodels-1.4.1-py3-none-any.whl (231 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/231.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.2/231.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imodels) (3.7.1)\n",
            "Requirement already satisfied: mlxtend>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from imodels) (0.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imodels) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from imodels) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from imodels) (2.31.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imodels) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from imodels) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from imodels) (4.66.1)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend>=0.18.0->imodels) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from mlxtend>=0.18.0->imodels) (67.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imodels) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imodels) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imodels) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imodels) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imodels) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imodels) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imodels) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->imodels) (2023.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imodels) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->imodels) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->imodels) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->imodels) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->imodels) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->imodels) (1.16.0)\n",
            "Installing collected packages: imodels\n",
            "Successfully installed imodels-1.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install imodels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install pmlb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D76aQM61j6Zi",
        "outputId": "358421a1-23ea-444a-cbd2-ae14ee11c39c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting pmlb',\n",
              " '  Downloading pmlb-1.0.1.post3-py3-none-any.whl (19 kB)',\n",
              " 'Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from pmlb) (1.5.3)',\n",
              " 'Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from pmlb) (2.31.0)',\n",
              " 'Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from pmlb) (6.0.1)',\n",
              " 'Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2.8.2)',\n",
              " 'Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (2023.4)',\n",
              " 'Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->pmlb) (1.23.5)',\n",
              " 'Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (3.3.2)',\n",
              " 'Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (3.6)',\n",
              " 'Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (2.0.7)',\n",
              " 'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24.0->pmlb) (2023.11.17)',\n",
              " 'Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.5->pmlb) (1.16.0)',\n",
              " 'Installing collected packages: pmlb',\n",
              " 'Successfully installed pmlb-1.0.1.post3']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.utils import check_random_state\n",
        "from imodels.util.data_util import get_clean_dataset\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#######################\n",
        "#     Functions       #\n",
        "#######################\n",
        "\n",
        "# Function to generate indices for random samples from a dataset\n",
        "def generate_sample_indices(random_state, n_samples):\n",
        "    random_instance = check_random_state(random_state)\n",
        "    sample_indices = random_instance.randint(0, n_samples, n_samples)\n",
        "    return sample_indices\n",
        "\n",
        "# Function to generate indices for samples that are not selected (out-of-bag samples)\n",
        "def generate_unsampled_indices(random_state, n_samples):\n",
        "    sample_indices = generate_sample_indices(random_state, n_samples)\n",
        "    sample_counts = np.bincount(sample_indices, minlength=n_samples)\n",
        "    unsampled_mask = sample_counts == 0\n",
        "    indices_range = np.arange(n_samples)\n",
        "    unsampled_indices = indices_range[unsampled_mask]\n",
        "    return unsampled_indices\n",
        "\n",
        "# Function to generate indices for random samples from a dataset\n",
        "def generate_sample_indices(random_state, n_samples):\n",
        "    random_instance = check_random_state(random_state)\n",
        "    sample_indices = random_instance.randint(0, n_samples, n_samples)\n",
        "    return sample_indices\n",
        "\n",
        "# Function to generate indices for samples that are not selected (out-of-bag samples)\n",
        "def generate_unsampled_indices(random_state, n_samples):\n",
        "    sample_indices = generate_sample_indices(random_state, n_samples)\n",
        "    sample_counts = np.bincount(sample_indices, minlength=n_samples)\n",
        "    unsampled_mask = sample_counts == 0\n",
        "    indices_range = np.arange(n_samples)\n",
        "    unsampled_indices = indices_range[unsampled_mask]\n",
        "    return unsampled_indices\n",
        "\n",
        "########################\n",
        "#       Classifier     #\n",
        "########################\n",
        "\n",
        "# Custom RandomForestClassifier class\n",
        "class CustomRandomForestClassifier(RandomForestClassifier):\n",
        "    def fit(self, X, y):\n",
        "        super().fit(X, y)\n",
        "        self.in_bag_indices_ = []\n",
        "        self.oob_indices_ = []\n",
        "        self.tree_weights_ = []\n",
        "\n",
        "        for estimator in self.estimators_:\n",
        "            random_state = estimator.random_state\n",
        "            in_bag_indices = generate_sample_indices(random_state, len(X))\n",
        "            oob_indices = generate_unsampled_indices(random_state, len(X))\n",
        "\n",
        "            self.in_bag_indices_.append(in_bag_indices)\n",
        "            self.oob_indices_.append(oob_indices)\n",
        "\n",
        "            if len(oob_indices) > 0:\n",
        "                oob_predictions = estimator.predict(X[oob_indices])\n",
        "                oob_loss = mean_squared_error(y[oob_indices], oob_predictions)\n",
        "                self.tree_weights_.append(np.exp(-oob_loss))\n",
        "            else:\n",
        "                self.tree_weights_.append(0)\n",
        "\n",
        "        # Normalize tree weights\n",
        "        total_weight = np.sum(self.tree_weights_)\n",
        "        if total_weight > 0:\n",
        "            self.tree_weights_ = [weight / total_weight for weight in self.tree_weights_]\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X, weights=None):\n",
        "        \"\"\"\n",
        "        Make predictions using the fitted custom random forest model.\n",
        "\n",
        "        Parameters:\n",
        "        - X: Input features for making predictions (numpy array or pandas DataFrame).\n",
        "        - weights (optional): The weighting scheme to use for aggregating predictions. Supported values:\n",
        "          \"expOOB\" (weights based on the exponential of the negative out-of-bag error) and \"uniform\"\n",
        "          (equal weighting). Defaults to \"uniform\" if not specified or if an unknown value is passed.\n",
        "\n",
        "        Returns:\n",
        "        - final_preds: An array of predicted class labels.\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"estimators_\"):\n",
        "            raise ValueError(\"The forest is not fitted yet!\")\n",
        "\n",
        "        weighted_preds = np.zeros((X.shape[0], len(self.classes_)))\n",
        "\n",
        "        if weights is None or weights not in [\"expOOB\", \"uniform\"]:\n",
        "            weights = \"uniform\"\n",
        "\n",
        "        if weights == \"expOOB\":\n",
        "            for tree, weight in zip(self.estimators_, self.tree_weights_):\n",
        "                preds = tree.predict_proba(X)\n",
        "                weighted_preds += weight * preds\n",
        "        elif weights == \"uniform\":\n",
        "            for tree in self.estimators_:\n",
        "                preds = tree.predict_proba(X)\n",
        "                weighted_preds += preds / len(self.estimators_)\n",
        "\n",
        "        final_preds = np.argmax(weighted_preds, axis=1)\n",
        "        return self.classes_[final_preds]\n",
        "\n",
        "\n",
        "    def predict_proba(self, X, weights=None):\n",
        "        if not hasattr(self, \"estimators_\"):\n",
        "            raise ValueError(\"The forest is not fitted yet!\")\n",
        "\n",
        "        weighted_preds = np.zeros((X.shape[0], len(self.classes_)))\n",
        "\n",
        "        if weights is None or weights not in [\"expOOB\", \"uniform\"]:\n",
        "            weights = \"uniform\"\n",
        "\n",
        "        if weights == \"expOOB\":\n",
        "            for tree, weight in zip(self.estimators_, self.tree_weights_):\n",
        "                preds = tree.predict_proba(X)\n",
        "                weighted_preds += weight * preds\n",
        "        elif weights == \"uniform\":\n",
        "            for tree in self.estimators_:\n",
        "                preds = tree.predict_proba(X)\n",
        "                weighted_preds += preds / len(self.estimators_)\n",
        "\n",
        "        return weighted_preds\n",
        "\n",
        "########################\n",
        "#       Regressor      #\n",
        "########################\n",
        "\n",
        "class CustomRandomForestRegressor(RandomForestRegressor):\n",
        "    \"\"\"\n",
        "    A custom RandomForestRegressor that allows for weighting trees based on their out-of-bag error.\n",
        "\n",
        "    Inherits from sklearn.ensemble.RandomForestRegressor.\n",
        "    \"\"\"\n",
        "    def fit(self, X, y):\n",
        "        super().fit(X, y)\n",
        "        self.in_bag_indices_ = []\n",
        "        self.oob_indices_ = []\n",
        "        self.tree_weights_ = []\n",
        "\n",
        "        for estimator in self.estimators_:\n",
        "            random_state = estimator.random_state\n",
        "            in_bag_indices = generate_sample_indices(random_state, len(X))\n",
        "            oob_indices = generate_unsampled_indices(random_state, len(X))\n",
        "\n",
        "            self.in_bag_indices_.append(in_bag_indices)\n",
        "            self.oob_indices_.append(oob_indices)\n",
        "\n",
        "            if len(oob_indices) > 0:\n",
        "                oob_predictions = estimator.predict(X[oob_indices])\n",
        "                oob_loss = mean_squared_error(y[oob_indices], oob_predictions)\n",
        "                self.tree_weights_.append(np.exp(-oob_loss))\n",
        "            else:\n",
        "                self.tree_weights_.append(0)\n",
        "\n",
        "        # Normalize tree weights\n",
        "        total_weight = np.sum(self.tree_weights_)\n",
        "        if total_weight > 0:\n",
        "            self.tree_weights_ = [weight / total_weight for weight in self.tree_weights_]\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X, weights=None):\n",
        "        \"\"\"\n",
        "        Predict using the forest of trees.\n",
        "\n",
        "        Parameters:\n",
        "        - X: array-like or sparse matrix of shape = [n_samples, n_features]\n",
        "        The input samples.\n",
        "\n",
        "        - weights: {'uniform', 'expOOB'} weighting scheme to use for aggregating predictions.\n",
        "          'uniform' will treat all trees equally, 'expOOB' will weight trees based on the exponential of the negative out-of-bag error.\n",
        "\n",
        "        Returns:\n",
        "        - y: array of shape = [n_samples]\n",
        "        The predicted values.\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"estimators_\"):\n",
        "            raise ValueError(\"The forest is not fitted yet!\")\n",
        "\n",
        "        if weights is None or weights not in [\"expOOB\", \"uniform\"]:\n",
        "            weights = \"uniform\"\n",
        "\n",
        "        # Collect predictions from each tree\n",
        "        all_preds = np.array([tree.predict(X) for tree in self.estimators_])\n",
        "        if weights == \"expOOB\":\n",
        "            # Use the exponential of the negative out-of-bag error as weights\n",
        "            weighted_preds = np.average(all_preds, axis=0, weights=self.tree_weights_)\n",
        "        elif weights == \"uniform\":\n",
        "            # All trees have equal weight\n",
        "            weighted_preds = np.mean(all_preds, axis=0)\n",
        "\n",
        "        return weighted_preds\n",
        "\n",
        "######################\n",
        "#     Evaluation     #\n",
        "######################\n",
        "\n",
        "def evaluate_datasets(datasets, task_type='classification', random_state=42):\n",
        "    \"\"\"\n",
        "    Evaluate datasets using the custom random forest model (classifier or regressor).\n",
        "\n",
        "    Parameters:\n",
        "    - datasets: list of dataset names to evaluate.\n",
        "    - task_type: 'classification' or 'regression', specifies the type of task.\n",
        "    - random_state: int, random state for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "    - df_scores: DataFrame containing the scores (ROC AUC for classification, RMSE for regression) for each dataset.\n",
        "    \"\"\"\n",
        "    scores_default = []\n",
        "    scores_expOOB = []\n",
        "\n",
        "    for dataset_name in datasets:\n",
        "        # Fetch the dataset\n",
        "        X, y, feature_names = get_clean_dataset(dataset_name)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=random_state)\n",
        "\n",
        "        if task_type == 'classification':\n",
        "            model = CustomRandomForestClassifier(oob_score=True, random_state=random_state)\n",
        "        elif task_type == 'regression':\n",
        "            model = CustomRandomForestRegressor(oob_score=True, random_state=random_state)\n",
        "        else:\n",
        "            raise ValueError(\"task_type must be 'classification' or 'regression'\")\n",
        "\n",
        "        # Initialize and train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions and evaluate\n",
        "        if task_type == 'classification':\n",
        "            # Using ROC AUC for classification\n",
        "            score_default = roc_auc_score(y_test, model.predict_proba(X_test, weights=\"uniform\")[:, 1])\n",
        "            score_expOOB = roc_auc_score(y_test, model.predict_proba(X_test, weights=\"expOOB\")[:, 1])\n",
        "        elif task_type == 'regression':\n",
        "            # Using RMSE for regression\n",
        "            score_default = sqrt(mean_squared_error(y_test, model.predict(X_test, weights=\"uniform\")))\n",
        "            score_expOOB = sqrt(mean_squared_error(y_test, model.predict(X_test, weights=\"expOOB\")))\n",
        "\n",
        "        scores_default.append(score_default)\n",
        "        scores_expOOB.append(score_expOOB)\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df_scores = pd.DataFrame({\n",
        "        'Dataset': datasets,\n",
        "        'Default': scores_default,\n",
        "        'expOOB': scores_expOOB\n",
        "    })\n",
        "\n",
        "    return df_scores\n",
        "\n",
        "# Define your datasets\n",
        "classification_datasets = [\"diabetes\", \"breast_cancer\", \"heart\", \"haberman\"]\n",
        "regression_datasets = [\"fico\", \"enhancer\", \"credit_g\", \"juvenile_clean\"]\n",
        "\n",
        "# Evaluate classification datasets\n",
        "df_classification_scores = evaluate_datasets(classification_datasets, task_type='classification')\n",
        "\n",
        "# Evaluate regression datasets\n",
        "df_regression_scores = evaluate_datasets(regression_datasets, task_type='regression')\n",
        "\n",
        "# Print scores for each dataset\n",
        "print(\"Classification Scores:\")\n",
        "print(df_classification_scores)\n",
        "print(\"=\"*100)\n",
        "print(\"\\nRegression Scores:\")\n",
        "print(df_regression_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbgvvdjhj6dE",
        "outputId": "fd91cbf4-9945-4085-de8b-02300153306d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fetching diabetes from pmlb\n",
            "fetching heart from imodels\n",
            "fetching fico from imodels\n",
            "fetching credit_g from imodels\n",
            "Classification Scores:\n",
            "         Dataset   Default    expOOB\n",
            "0       diabetes  0.830926  0.830370\n",
            "1  breast_cancer  0.828231  0.828231\n",
            "2          heart  0.915584  0.916306\n",
            "3       haberman  0.624369  0.623737\n",
            "====================================================================================================\n",
            "\n",
            "Regression Scores:\n",
            "          Dataset   Default    expOOB\n",
            "0            fico  0.448790  0.448789\n",
            "1        enhancer  0.245904  0.245917\n",
            "2        credit_g  0.398569  0.398691\n",
            "3  juvenile_clean  0.262467  0.262477\n"
          ]
        }
      ]
    }
  ]
}